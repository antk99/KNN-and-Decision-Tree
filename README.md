# K-Nearest Neighbors & Decision Tree

We implemented the K-Nearest neighbors and decision tree classification algorithms from scratch in Python for health data classification. Here's what we did:

## Task 1: Data Acquisition and Preprocessing

- We acquired two datasets: hepatitis.csv (Hepatitis dataset) and messidorfeatures.arff (Diabetic Retinopathy Debrecen dataset).

- Data cleaning included handling missing or malformed features. We removed examples with missing values to ensure data integrity.

- Basic data statistics were computed to understand class distributions and key features.

## Task 2: Model Implementation

- We implemented K-Nearest Neighbour and Decision Tree models from scratch.

- Python classes were created for both models, initializing model parameters and defining essential functions: fit, predict, and evaluate_acc.

## Task 3: Running Experiments

- We conducted a series of experiments to compare features and models, using accuracy as the performance metric.

- Key experiments included comparing K-Nearest Neighbour and Decision Tree accuracy, testing different K values, and exploring the impact of maximum tree depth and cost functions.

- We visualized decision boundaries and described their key features.

## Deliverables
- Submitted two files as specified:
    1. **Code**: Containing the implemented KNN & Decision Tree algorithms, training, and experiment code.
    2. **Report**: A scientific report discussing the contents of this project.
